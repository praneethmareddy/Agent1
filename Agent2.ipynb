{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üß† LangGraph + MCP + Ollama\n",
        "## PLAN ‚Üî USER LOOP ‚Üí ACT Autonomous Agent\n",
        "\n",
        "Features:\n",
        "- Infinite PLAN refinement\n",
        "- Human approval gate\n",
        "- Fully autonomous ACT\n",
        "- MCP filesystem tools\n",
        "- Notebook safe (no async servers)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install -U langgraph langchain langchain-ollama mcp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from typing import TypedDict, List, Dict\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_ollama import ChatOllama\n",
        "import os, json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "llm = ChatOllama(\n",
        "    model=\"gpt-oss:20b\",\n",
        "    temperature=0\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Agent State"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class AgentState(TypedDict):\n",
        "    goal: str\n",
        "    plan: List[str]\n",
        "    mode: str          # plan | act\n",
        "    messages: List[Dict]\n",
        "    done: bool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MCP Filesystem Tools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from mcp.server.fastmcp import FastMCP\n",
        "\n",
        "BASE_DIR = \"/tmp/mcp_workspace\"\n",
        "os.makedirs(BASE_DIR, exist_ok=True)\n",
        "\n",
        "mcp = FastMCP(\"filesystem\")\n",
        "\n",
        "@mcp.tool()\n",
        "def list_dir(path: str = \".\"):\n",
        "    return os.listdir(os.path.join(BASE_DIR, path))\n",
        "\n",
        "@mcp.tool()\n",
        "def read_file(path: str) -> str:\n",
        "    return open(os.path.join(BASE_DIR, path)).read()\n",
        "\n",
        "@mcp.tool()\n",
        "def write_file(path: str, content: str) -> str:\n",
        "    with open(os.path.join(BASE_DIR, path), \"w\") as f:\n",
        "        f.write(content)\n",
        "    return \"ok\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def list_tools():\n",
        "    return list(mcp._tools.keys())\n",
        "\n",
        "def call_tool(name, args):\n",
        "    return mcp._tools[name](**args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Planner Node (PLAN MODE)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def planner_node(state: AgentState) -> AgentState:\n",
        "    prompt = f\"\"\"\n",
        "You are an AI planner.\n",
        "\n",
        "User request:\n",
        "{state['goal']}\n",
        "\n",
        "Current plan:\n",
        "{state['plan']}\n",
        "\n",
        "Rules:\n",
        "- If no plan exists, create one\n",
        "- If plan exists, modify ONLY what user asked\n",
        "- Do NOT execute anything\n",
        "- Output numbered steps only\n",
        "\"\"\"\n",
        "\n",
        "plan_text = llm.invoke(prompt).content\n",
        "state['plan'] = [l.strip() for l in plan_text.splitlines() if l.strip()]\n",
        "state['done'] = False\n",
        "return state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Executor Node (ACT MODE)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def executor_node(state: AgentState) -> AgentState:\n",
        "    tools = list_tools()\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are an autonomous agent.\n",
        "\n",
        "Goal: {state['goal']}\n",
        "Plan: {state['plan']}\n",
        "History: {state['messages']}\n",
        "\n",
        "Available tools:\n",
        "{tools}\n",
        "\n",
        "Decide ONE next action.\n",
        "\n",
        "Return ONLY JSON:\n",
        "{{\"tool\": \"<tool|done>\", \"args\": {{}}}}\n",
        "\"\"\"\n",
        "\n",
        "action = json.loads(llm.invoke(prompt).content)\n",
        "\n",
        "if action['tool'] == 'done':\n",
        "    state['done'] = True\n",
        "    return state\n",
        "\n",
        "state['messages'].append(action)\n",
        "return state"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def tool_node(state: AgentState) -> AgentState:\n",
        "    action = state['messages'][-1]\n",
        "    result = call_tool(action['tool'], action.get('args', {}))\n",
        "    state['messages'].append({'observation': result})\n",
        "    return state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PLAN Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plan_graph = StateGraph(AgentState)\n",
        "plan_graph.add_node(\"planner\", planner_node)\n",
        "plan_graph.set_entry_point(\"planner\")\n",
        "plan_graph.add_edge(\"planner\", END)\n",
        "plan_app = plan_graph.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ACT Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "act_graph = StateGraph(AgentState)\n",
        "act_graph.add_node(\"executor\", executor_node)\n",
        "act_graph.add_node(\"tool\", tool_node)\n",
        "act_graph.set_entry_point(\"executor\")\n",
        "act_graph.add_conditional_edges(\n",
        "    \"executor\",\n",
        "    lambda s: END if s['done'] else 'tool'\n",
        ")\n",
        "act_graph.add_edge(\"tool\", \"executor\")\n",
        "act_app = act_graph.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß™ PLAN MODE Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "state = {\n",
        "    'goal': 'Read x1.txt and x2.txt and write a combined summary into summary.txt',\n",
        "    'plan': [],\n",
        "    'mode': 'plan',\n",
        "    'messages': [],\n",
        "    'done': False\n",
        "}\n",
        "\n",
        "state = plan_app.invoke(state)\n",
        "state['plan']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚úèÔ∏è User Modifies Plan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "state['goal'] = 'Change summary.txt to summ.txt'\n",
        "state = plan_app.invoke(state)\n",
        "state['plan']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ ACT MODE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "state['mode'] = 'act'\n",
        "state = act_app.invoke(state)\n",
        "state['messages']"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
