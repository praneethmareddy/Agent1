{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph + MCP (Notebook-safe) + Ollama Autonomous Agent\n",
    "\n",
    "**PLAN → Human Approval → ACT (Autonomous)**\n",
    "\n",
    "- No ClientSession\n",
    "- No stdio\n",
    "- Notebook-safe MCP tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U langgraph langchain langchain-ollama mcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Dict\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_ollama import ChatOllama\n",
    "import json, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(\n",
    "    model=\"qwen2.5:7b\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent State (Generic & Future-proof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    goal: str\n",
    "    plan: List[str]\n",
    "    approved: bool\n",
    "    messages: List[Dict]\n",
    "    done: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCP Tools (Notebook-safe, In-process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcp.server.fastmcp import FastMCP\n",
    "\n",
    "BASE_DIR = \"/tmp/mcp_workspace\"\n",
    "os.makedirs(BASE_DIR, exist_ok=True)\n",
    "\n",
    "mcp_server = FastMCP(\"filesystem\")\n",
    "\n",
    "@mcp_server.tool()\n",
    "def list_dir(path: str = \".\"):\n",
    "    return os.listdir(os.path.join(BASE_DIR, path))\n",
    "\n",
    "@mcp_server.tool()\n",
    "def read_file(path: str) -> str:\n",
    "    return open(os.path.join(BASE_DIR, path)).read()\n",
    "\n",
    "@mcp_server.tool()\n",
    "def write_file(path: str, content: str) -> str:\n",
    "    with open(os.path.join(BASE_DIR, path), \"w\") as f:\n",
    "        f.write(content)\n",
    "    return \"ok\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCP Tool Access Helpers (NO ClientSession)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_tools():\n",
    "    return list(mcp_server._tools.keys())\n",
    "\n",
    "def call_tool(tool_name: str, args: dict):\n",
    "    tool = mcp_server._tools[tool_name]\n",
    "    return tool(**args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planner Node (PLAN MODE – LLM only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def planner_node(state: AgentState) -> AgentState:\n",
    "    prompt = f\"\"\"\n",
    "    You are an AI planner.\n",
    "\n",
    "    Goal:\n",
    "    {state['goal']}\n",
    "\n",
    "    Create a clear step-by-step plan.\n",
    "    Do NOT execute anything.\n",
    "    \"\"\"\n",
    "\n",
    "    plan_text = llm.invoke(prompt).content\n",
    "\n",
    "    state[\"plan\"] = [l for l in plan_text.splitlines() if l.strip()]\n",
    "    state[\"approved\"] = False\n",
    "    state[\"messages\"] = []\n",
    "    state[\"done\"] = False\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executor Node (LLM chooses tools autonomously)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executor_node(state: AgentState) -> AgentState:\n",
    "    tools = list_tools()\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are an autonomous agent.\n",
    "\n",
    "    Goal: {state['goal']}\n",
    "    Plan: {state['plan']}\n",
    "    History: {state['messages']}\n",
    "\n",
    "    Available tools:\n",
    "    {tools}\n",
    "\n",
    "    Decide ONE next action.\n",
    "\n",
    "    Respond ONLY in JSON:\n",
    "    {{\n",
    "      \\\"tool\\\": \\\"<tool_name | done>\\\",\n",
    "      \\\"args\\\": {{ }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    action = json.loads(llm.invoke(prompt).content)\n",
    "\n",
    "    if action[\"tool\"] == \"done\":\n",
    "        state[\"done\"] = True\n",
    "        return state\n",
    "\n",
    "    state[\"messages\"].append(action)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Runner Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_node(state: AgentState) -> AgentState:\n",
    "    action = state[\"messages\"][-1]\n",
    "\n",
    "    result = call_tool(\n",
    "        action[\"tool\"],\n",
    "        action.get(\"args\", {})\n",
    "    )\n",
    "\n",
    "    state[\"messages\"].append({\"observation\": result})\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"planner\", planner_node)\n",
    "graph.add_node(\"executor\", executor_node)\n",
    "graph.add_node(\"tool\", tool_node)\n",
    "\n",
    "graph.set_entry_point(\"planner\")\n",
    "graph.add_edge(\"planner\", \"WAIT\")\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"WAIT\",\n",
    "    lambda s: \"executor\" if s[\"approved\"] else \"WAIT\"\n",
    ")\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"executor\",\n",
    "    lambda s: END if s[\"done\"] else \"tool\"\n",
    ")\n",
    "\n",
    "graph.add_edge(\"tool\", \"executor\")\n",
    "\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run PLAN MODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "    \"goal\": \"Read docs and write short notes into summary.txt\",\n",
    "    \"plan\": [],\n",
    "    \"approved\": False,\n",
    "    \"messages\": [],\n",
    "    \"done\": False\n",
    "}\n",
    "\n",
    "state = app.invoke(state)\n",
    "state[\"plan\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User clicks ACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state[\"approved\"] = True\n",
    "state = app.invoke(state)\n",
    "state[\"messages\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": \"Python 3\",
   "language\": \"python\",
   "name\": \"python3\"
  },
  "language_info\": {
   "name\": \"python\",
   "version\": \"3.10\"
  }
 },
 \"nbformat\": 4,
 \"nbformat_minor\": 5
}
